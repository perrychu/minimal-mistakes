Useful links for setting up Spark.

### Setting up EMR
* [AWS IAM permissions for EMR](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-spark-launch.html)
* [Default role set-up for EMR to use EC2](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-iam-roles-defaultroles.html)

### Setting up Spark on EMR
* [Spark & Zeppelin on EMR](https://dziganto.github.io/amazon%20emr/apache%20spark/apache%20zeppelin/big%20data/From-Zero-to-Spark-Cluster-in-Under-Ten-Minutes/)

### Setting up Spark on Docker (local / EC2)
* [Installing jupyter/pyspark-notebook](http://maxmelnick.com/2016/06/04/spark-docker.html)
* [jupyter/pyspark-notebook docs](https://github.com/jupyter/docker-stacks/tree/master/pyspark-notebook)

### Getting pyspark to run with python / jupyter
Note: In an EMR cluster, spark is located in /usr/lib/spark (as of this post date // EMR v5.13.0)
* [If you don't want to think about details](https://blog.sicara.com/get-started-pyspark-jupyter-guide-tutorial-ae2fe84f594f)
* [Explanation](https://stackoverflow.com/questions/23256536/importing-pyspark-in-python-shell/#47896850)
* [findspark documentation](https://github.com/minrk/findspark)
* [Walkthrough without findspark](https://mapr.com/blog/configure-jupyter-spark-python/)

### Spark & S3
* [Spark & S3 Setup](https://sparkour.urizone.net/recipes/using-s3/)
* [Description of hadoop-aws s3 interfaces](https://wiki.apache.org/hadoop/AmazonS3)
* More about hadoop-aws dependency / code examples:
  * https://stackoverflow.com/questions/41062705/reading-multiple-files-from-s3-in-parallel-spark-java
  * https://tech.kinja.com/how-not-to-pull-from-s3-using-apache-spark-1704509219
  * https://forums.databricks.com/questions/480/how-do-i-ingest-a-large-number-of-files-from-s3-my.html
  * https://medium.com/@subhojit20_27731/apache-spark-and-amazon-s3-gotchas-and-best-practices-a767242f3d98
* [Parallel loading to Spark RDDs](https://stackoverflow.com/questions/41062705/reading-multiple-files-from-s3-in-parallel-spark-java)
* [Spark Dataframes (parallel by default??)](https://spark.apache.org/docs/latest/sql-programming-guide.html)
* [Efficient load for large # of semi-structured files (e.g. JSON, CSV)](https://szczeles.github.io/Reading-JSON-CSV-and-XML-files-efficiently-in-Apache-Spark/)

### Spark Configuration
* [Config Values Guide / Spreadsheet](http://c2fo.io/c2fo/spark/aws/emr/2016/07/06/apache-spark-config-cheatsheet/)
* [Optimizations](https://discourse.snowplowanalytics.com/t/learnings-from-using-the-new-spark-emr-jobs/1260)
* [Spark Config Documentation](https://spark.apache.org/docs/2.2.0/configuration.html#available-properties)
* [Spark Session Docs (place to set settings)](https://spark.apache.org/docs/2.2.0/api/python/pyspark.sql.html#pyspark.sql.SparkSession)
* [EMR Config Documentation](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-spark-configure.html)
* [Tips / lessons learned](https://dlab.epfl.ch/2017-09-30-what-i-learned-from-processing-big-data-with-spark/)
* [Common errors & fixes](https://www.indix.com/blog/engineering/lessons-from-using-spark-to-process-large-amounts-of-data-part-i/)

### Using Spark
* [Intro to pyspark](https://www.datacamp.com/community/tutorials/apache-spark-python)
* [Zeppelin vs. Jupyter](https://dwhsys.com/2017/03/25/apache-zeppelin-vs-jupyter-notebook/)
